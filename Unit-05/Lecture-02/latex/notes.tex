\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\graphicspath{{../images/}}
\usepackage{hyperref}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 05 -- Lecture 02 Notes\\Feature Selection Methods (Filter/Wrapper/Embedded)}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{Topic}
Filter, wrapper, and embedded feature selection methods (overview).
\section*{How to Use These Notes}
These notes are written for students who are seeing the topic for the first time. They
follow the slide order, but add the missing 'why', interpretation, and common mistakes. If
you get stuck, look at the worked exercises and then run the Python demo.

Course repository (slides, demos, datasets): \url{https://github.com/tali7c/Statistics-and-Data-Analysis}

\section*{Time Plan (55 minutes)}
\begin{itemize}
  \item 0--10 min: Attendance + recap of previous lecture
  \item 10--35 min: Core concepts (this lecture's sections)
  \item 35--45 min: Exercises (solve 1--2 in class, rest as practice)
  \item 45--50 min: Mini demo + interpretation of output
  \item 50--55 min: Buffer / wrap-up (leave 5 minutes early)
\end{itemize}

\section*{Slide-by-slide Notes}
\subsection*{Title Slide}
State the lecture title clearly and connect it to what students already know.
Tell students what they will be able to do by the end (not just what you will cover).

\subsection*{Quick Links / Agenda}
Explain the structure of the lecture and where the exercises and demo appear.
\begin{itemize}
  \item Overview
  \item Filter Methods
  \item Wrapper/Embedded
  \item Exercises
  \item Demo
  \item Summary
\end{itemize}

\subsection*{Learning Outcomes}
\begin{itemize}
  \item Explain filter methods (variance, correlation, mutual information)
  \item Explain wrapper methods (RFE) at a high level
  \item Explain embedded methods (lasso, tree importance) at a high level
  \item Discuss pros/cons of each approach
\end{itemize}
\paragraph{Why these outcomes matter.}
\textbf{Correlation} measures the strength of a linear association between two variables. It
is symmetric (no X/Y direction) and does not imply causation. Outliers can inflate or hide
correlation, so always look at the scatter plot.
\textbf{Lasso (L1)} can shrink some coefficients exactly to zero, acting like automatic
feature selection. This can improve interpretability, but it can be unstable when predictors
are highly correlated.

\subsection*{Filter Methods: Key Points}
\begin{itemize}
  \item Fast scoring without training many models
  \item Examples: variance threshold, correlation with target
  \item May miss interactions
\end{itemize}
\paragraph{Explanation.}
\textbf{Correlation} measures the strength of a linear association between two variables. It
is symmetric (no X/Y direction) and does not imply causation. Outliers can inflate or hide
correlation, so always look at the scatter plot.

\subsection*{Wrapper/Embedded: Key Points}
\begin{itemize}
  \item Wrapper: search subsets using a model (slow)
  \item Embedded: selection during training (lasso, trees)
\end{itemize}
\paragraph{Explanation.}
\textbf{Lasso (L1)} can shrink some coefficients exactly to zero, acting like automatic
feature selection. This can improve interpretability, but it can be unstable when predictors
are highly correlated.

\subsection*{Exercises (with Solutions)}
Attempt the exercise first, then compare with the solution. Focus on interpretation, not
only arithmetic.

\subsection*{Exercise 1: Low variance}
If a feature is almost constant, keep it?
\subsubsection*{Solution}
\begin{itemize}
  \item Usually no; low variance adds little information.
\end{itemize}

\subsection*{Exercise 2: Redundant features}
Two features have corr=0.99. What might you do?
\subsubsection*{Solution}
\begin{itemize}
  \item Drop one or use regularization/PCA.
\end{itemize}
\paragraph{Walkthrough.}
\textbf{PCA} finds new axes (principal components) that capture maximum variance. It is a
rotation of the feature space. Because PCA is variance-based, it is sensitive to scaling:
standardize features first unless all features are already comparable.

\subsection*{Exercise 3: Wrapper trade-off}
Why is RFE slower than filters?
\subsubsection*{Solution}
\begin{itemize}
  \item It trains many models on many subsets.
\end{itemize}

\subsection*{Mini Demo (Python)}
Run from the lecture folder:
\begin{verbatim}
python demo/demo.py
\end{verbatim}

Output files:
\begin{itemize}
  \item \texttt{images/demo.png}
  \item \texttt{data/results.txt}
\end{itemize}
\paragraph{What to show and say.}
\begin{itemize}
  \item Creates many features and demonstrates a simple selection approach.
  \item Shows how removing noisy/redundant features can improve validation score.
  \item Use it to compare filter vs wrapper vs embedded ideas conceptually.
\end{itemize}

\subsection*{Demo Output (Example)}
\begin{center}
\IfFileExists{../images/demo.png}{
  \includegraphics[width=0.95\linewidth]{../images/demo.png}
}{
  \small (Run the demo to generate \texttt{images/demo.png})
}
\end{center}

\subsection*{Summary}
\begin{itemize}
  \item Key definitions and the main formula.
  \item How to interpret results in context.
  \item How the demo connects to the theory.
\end{itemize}

\subsection*{Exit Question}
When would you prefer a fast filter method over a wrapper method?
\paragraph{Suggested answer (for revision).}
Use fast filters when you have many features and limited compute/time, or as an initial
screening before more expensive wrappers.

\section*{References}
\begin{itemize}
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}, Wiley.
  \item Devore, J. L. \textit{Probability and Statistics for Engineering and the Sciences}, Cengage.
  \item McKinney, W. \textit{Python for Data Analysis}, O'Reilly.
\end{itemize}

% BEGIN SLIDE APPENDIX (AUTO-GENERATED)
\clearpage
\section*{Appendix: Slide Deck Content (Reference)}
\noindent The material below is a reference copy of the slide deck content. Exercise solutions are explained in the main notes where applicable.

\subsection*{Title Slide}
\titlepage
        \vspace{-0.5em}
        \begin{center}
          \small \texttt{https://github.com/tali7c/Statistics-and-Data-Analysis}
        \end{center}
\subsection*{Quick Links}
\centering
        \textbf{Overview}\hspace{0.6em}
\textbf{Filter Methods}\hspace{0.6em}
\textbf{Wrapper/Embedded}\hspace{0.6em}
\textbf{Exercises}\hspace{0.6em}
\textbf{Demo}\hspace{0.6em}
\textbf{Summary}\hspace{0.6em}
\subsection*{Agenda}
\begin{itemize}
  \item Overview
  \item Filter Methods
  \item Wrapper/Embedded
  \item Exercises
  \item Demo
  \item Summary
\end{itemize}
\subsection*{Learning Outcomes}
\begin{itemize}
        \item Explain filter methods (variance, correlation, mutual information)
\item Explain wrapper methods (RFE) at a high level
\item Explain embedded methods (lasso, tree importance) at a high level
\item Discuss pros/cons of each approach
      \end{itemize}
\subsection*{Filter Methods: Key Points}
\begin{itemize}
        \item Fast scoring without training many models
\item Examples: variance threshold, correlation with target
\item May miss interactions
      \end{itemize}
\subsection*{Wrapper/Embedded: Key Points}
\begin{itemize}
        \item Wrapper: search subsets using a model (slow)
\item Embedded: selection during training (lasso, trees)
      \end{itemize}
\subsection*{Exercise 1: Low variance}
\small
  If a feature is almost constant, keep it?
\subsection*{Solution 1}
\begin{itemize}
    \item Usually no; low variance adds little information.
  \end{itemize}
\subsection*{Exercise 2: Redundant features}
\small
  Two features have corr=0.99. What might you do?
\subsection*{Solution 2}
\begin{itemize}
    \item Drop one or use regularization/PCA.
  \end{itemize}
\subsection*{Exercise 3: Wrapper trade-off}
\small
  Why is RFE slower than filters?
\subsection*{Solution 3}
\begin{itemize}
    \item It trains many models on many subsets.
  \end{itemize}
\subsection*{Mini Demo (Python)}
Run from the lecture folder:
  \begin{center}
    \texttt{python demo/demo.py}
  \end{center}
  \vspace{0.4em}
  Outputs:
  \begin{itemize}
    \item \texttt{images/demo.png}
    \item \texttt{data/results.txt}
  \end{itemize}
\subsection*{Demo Output (Example)}
\begin{center}
  \IfFileExists{../images/demo.png}{
    \includegraphics[width=0.92\linewidth]{demo.png}
  }{
    \small (Run demo to generate: \texttt{demo.png})
  }
  \end{center}
\subsection*{Summary}
\begin{itemize}
        \item Key definitions and the main formula.
\item How to interpret results in context.
\item How the demo connects to the theory.
      \end{itemize}
\subsection*{Exit Question}
\small
  When would you prefer a fast filter method over a wrapper method?
% END SLIDE APPENDIX (AUTO-GENERATED)

\end{document}
