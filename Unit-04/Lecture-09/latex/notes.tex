\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{graphicx}
\graphicspath{{../images/}}
\usepackage{hyperref}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 04 -- Lecture 09 Notes\\Case Study: End-to-End Regression Workflow}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{Topic}
End-to-end workflow: data -> model -> evaluation -> communication (case style).
\section*{How to Use These Notes}
These notes are written for students who are seeing the topic for the first time. They
follow the slide order, but add the missing 'why', interpretation, and common mistakes. If
you get stuck, look at the worked exercises and then run the Python demo.

Course repository (slides, demos, datasets): \url{https://github.com/tali7c/Statistics-and-Data-Analysis}

\section*{Time Plan (55 minutes)}
\begin{itemize}
  \item 0--10 min: Attendance + recap of previous lecture
  \item 10--35 min: Core concepts (this lecture's sections)
  \item 35--45 min: Exercises (solve 1--2 in class, rest as practice)
  \item 45--50 min: Mini demo + interpretation of output
  \item 50--55 min: Buffer / wrap-up (leave 5 minutes early)
\end{itemize}

\section*{Slide-by-slide Notes}
\subsection*{Title Slide}
State the lecture title clearly and connect it to what students already know.
Tell students what they will be able to do by the end (not just what you will cover).

\subsection*{Quick Links / Agenda}
Explain the structure of the lecture and where the exercises and demo appear.
\begin{itemize}
  \item Overview
  \item Workflow
  \item Evaluation
  \item Exercises
  \item Demo
  \item Summary
\end{itemize}

\subsection*{Learning Outcomes}
\begin{itemize}
  \item Describe an end-to-end regression workflow
  \item Choose appropriate regression metrics (RMSE and $R^2$)
  \item Check overfitting (train vs test gap)
  \item Communicate results with plots (predicted vs actual, residuals)
\end{itemize}
\paragraph{Why these outcomes matter.}
\textbf{Regression} models a response variable $Y$ as a function of predictor(s) $X$. It has
direction (predictors -> response), produces a fitted equation, and lets you predict and
explain. Regression is not automatically causal; causality needs design or strong
assumptions.
A \textbf{residual} is $y - \hat{y}$. Residual plots tell you what the model failed to
explain. Patterns in residuals (trend, curvature, changing variance) are warnings that your
model form is inadequate or assumptions are violated.

\subsection*{Workflow: Key Points}
\begin{itemize}
  \item Define target and inputs
  \item Prepare data and split chronologically if needed
  \item Fit baseline then iterate
\end{itemize}

\subsection*{Evaluation: Key Points}
\begin{itemize}
  \item Use RMSE/MSE/MAE and $R^2$
  \item Use plots: predicted vs actual, residuals
  \item Document limitations
\end{itemize}
\paragraph{Explanation.}
A \textbf{residual} is $y - \hat{y}$. Residual plots tell you what the model failed to
explain. Patterns in residuals (trend, curvature, changing variance) are warnings that your
model form is inadequate or assumptions are violated.
$R^2$ is the fraction of variance in $Y$ explained by the model (in-sample). It increases
when you add predictors, even useless ones, so it is not a guarantee of a good model. Use
residual diagnostics and out-of-sample evaluation to judge model quality.

\subsection*{Exercises (with Solutions)}
Attempt the exercise first, then compare with the solution. Focus on interpretation, not
only arithmetic.

\subsection*{Exercise 1: Metric choice}
Target is continuous (price). Should you use accuracy?
\subsubsection*{Solution}
\begin{itemize}
  \item No; accuracy is for classification.
\end{itemize}

\subsection*{Exercise 2: Overfitting sign}
Train RMSE=5, test RMSE=20. What does it suggest?
\subsubsection*{Solution}
\begin{itemize}
  \item Overfitting; try simpler model or regularization.
\end{itemize}

\subsection*{Exercise 3: Communication}
Name one plot to communicate regression quality.
\subsubsection*{Solution}
\begin{itemize}
  \item Predicted vs actual scatter; residual plot.
\end{itemize}
\paragraph{Walkthrough.}
\textbf{Regression} models a response variable $Y$ as a function of predictor(s) $X$. It has
direction (predictors -> response), produces a fitted equation, and lets you predict and
explain. Regression is not automatically causal; causality needs design or strong
assumptions.
A \textbf{residual} is $y - \hat{y}$. Residual plots tell you what the model failed to
explain. Patterns in residuals (trend, curvature, changing variance) are warnings that your
model form is inadequate or assumptions are violated.

\subsection*{Mini Demo (Python)}
Run from the lecture folder:
\begin{verbatim}
python demo/demo.py
\end{verbatim}

Output files:
\begin{itemize}
  \item \texttt{images/demo.png}
  \item \texttt{data/results.txt}
\end{itemize}
\paragraph{What to show and say.}
\begin{itemize}
  \item Builds an end-to-end regression mini-case (split -> fit -> evaluate).
  \item Produces a diagnostic plot and numeric metrics to practice reporting.
  \item Use it to show what a 'good report' looks like (assumptions + limits).
\end{itemize}

\subsection*{Demo Output (Example)}
\begin{center}
\IfFileExists{../images/demo.png}{
  \includegraphics[width=0.95\linewidth]{../images/demo.png}
}{
  \small (Run the demo to generate \texttt{images/demo.png})
}
\end{center}

\subsection*{Summary}
\begin{itemize}
  \item Key definitions and the main formula.
  \item How to interpret results in context.
  \item How the demo connects to the theory.
\end{itemize}

\subsection*{Exit Question}
What would you do first if the case study model performs poorly on the test set?
\paragraph{Suggested answer (for revision).}
Start by checking data leakage and split strategy, then compare to a simple baseline and
inspect residuals/feature issues before adding complexity.

\section*{References}
\begin{itemize}
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}, Wiley.
  \item Devore, J. L. \textit{Probability and Statistics for Engineering and the Sciences}, Cengage.
  \item McKinney, W. \textit{Python for Data Analysis}, O'Reilly.
\end{itemize}

% BEGIN SLIDE APPENDIX (AUTO-GENERATED)
\clearpage
\section*{Appendix: Slide Deck Content (Reference)}
\noindent The material below is a reference copy of the slide deck content. Exercise solutions are explained in the main notes where applicable.

\subsection*{Title Slide}
\titlepage
        \vspace{-0.5em}
        \begin{center}
          \small \texttt{https://github.com/tali7c/Statistics-and-Data-Analysis}
        \end{center}
\subsection*{Quick Links}
\centering
        \textbf{Overview}\hspace{0.6em}
\textbf{Workflow}\hspace{0.6em}
\textbf{Evaluation}\hspace{0.6em}
\textbf{Exercises}\hspace{0.6em}
\textbf{Demo}\hspace{0.6em}
\textbf{Summary}\hspace{0.6em}
\subsection*{Agenda}
\begin{itemize}
  \item Overview
  \item Workflow
  \item Evaluation
  \item Exercises
  \item Demo
  \item Summary
\end{itemize}
\subsection*{Learning Outcomes}
\begin{itemize}
        \item Describe an end-to-end regression workflow
\item Choose appropriate regression metrics (RMSE and $R^2$)
\item Check overfitting (train vs test gap)
\item Communicate results with plots (predicted vs actual, residuals)
      \end{itemize}
\subsection*{Workflow: Key Points}
\begin{itemize}
        \item Define target and inputs
\item Prepare data and split chronologically if needed
\item Fit baseline then iterate
      \end{itemize}
\subsection*{Evaluation: Key Points}
\begin{itemize}
        \item Use RMSE/MSE/MAE and $R^2$
\item Use plots: predicted vs actual, residuals
\item Document limitations
      \end{itemize}
\subsection*{Exercise 1: Metric choice}
\small
  Target is continuous (price). Should you use accuracy?
\subsection*{Solution 1}
\begin{itemize}
    \item No; accuracy is for classification.
  \end{itemize}
\subsection*{Exercise 2: Overfitting sign}
\small
  Train RMSE=5, test RMSE=20. What does it suggest?
\subsection*{Solution 2}
\begin{itemize}
    \item Overfitting; try simpler model or regularization.
  \end{itemize}
\subsection*{Exercise 3: Communication}
\small
  Name one plot to communicate regression quality.
\subsection*{Solution 3}
\begin{itemize}
    \item Predicted vs actual scatter; residual plot.
  \end{itemize}
\subsection*{Mini Demo (Python)}
Run from the lecture folder:
  \begin{center}
    \texttt{python demo/demo.py}
  \end{center}
  \vspace{0.4em}
  Outputs:
  \begin{itemize}
    \item \texttt{images/demo.png}
    \item \texttt{data/results.txt}
  \end{itemize}
\subsection*{Demo Output (Example)}
\begin{center}
  \IfFileExists{../images/demo.png}{
    \includegraphics[width=0.92\linewidth]{demo.png}
  }{
    \small (Run demo to generate: \texttt{demo.png})
  }
  \end{center}
\subsection*{Summary}
\begin{itemize}
        \item Key definitions and the main formula.
\item How to interpret results in context.
\item How the demo connects to the theory.
      \end{itemize}
\subsection*{Exit Question}
\small
  What would you do first if the case study model performs poorly on the test set?
% END SLIDE APPENDIX (AUTO-GENERATED)

\end{document}
