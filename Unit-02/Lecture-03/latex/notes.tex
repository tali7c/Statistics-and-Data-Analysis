\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{listings}
\usepackage{xcolor}
\usepackage{graphicx}
\graphicspath{{../images/}}
\usepackage{amssymb}
\usepackage{booktabs}
\usepackage{hyperref}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 02 -- Lecture 03 Notes\\Correlation, Skewness, Kurtosis}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{What You Will Learn (Beginner-Friendly)}
This lecture answers two practical questions:
\begin{enumerate}
  \item If two variables (like study hours and score) move together, how do we measure the \emph{strength} of that relationship?
  \item If we look at one variable (like income), how do we describe the \emph{shape} of its distribution beyond center and spread?
\end{enumerate}

By the end, you should be able to:
\begin{itemize}
  \item Define \textbf{Pearson correlation} and compute it on small paired datasets.
  \item Explain why correlation is \textbf{scale-free} and how it relates to covariance.
  \item Explain key cautions: \textbf{outliers}, \textbf{non-linearity}, and \textbf{correlation vs causation}.
  \item Interpret \textbf{skewness} (right/left skew) and \textbf{kurtosis} (tail heaviness).
  \item Compute simple \textbf{moment skewness} and \textbf{excess kurtosis} for small datasets.
\end{itemize}

\section*{1. Correlation}

\subsection*{1.1 Intuition}
Correlation measures \textbf{linear association} between two variables.
If a scatter plot looks like an upward sloping line, correlation is positive.
If it looks like a downward sloping line, correlation is negative.

\subsection*{1.2 Pearson correlation formula}
For paired observations $(x_i,y_i)$, the Pearson correlation is:
\[
r = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}
         {\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}}
\]
Key facts:
\begin{itemize}
  \item $-1 \le r \le 1$.
  \item The sign ($+$ or $-$) shows direction (increase together vs opposite).
  \item The magnitude $|r|$ shows strength of \emph{linear} relationship.
  \item Correlation is \textbf{unitless} (scale-free).
\end{itemize}

\subsection*{1.3 Correlation vs covariance}
In Lecture 02 we computed \textbf{sample covariance}:
\[
s_{xy}=\frac{1}{n-1}\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})
\]
Correlation is the standardized version:
\[
r=\frac{s_{xy}}{s_x s_y}
\]
where $s_x$ and $s_y$ are sample standard deviations.

\paragraph{Why ``scale-free'' matters.}
If we change units (hours to minutes, marks to percentage), covariance changes because its units change.
But correlation does \emph{not} change, because the scaling affects the numerator and denominator in the same way.

\subsection*{1.4 Common pitfalls}
\begin{itemize}
  \item \textbf{Outliers:} a single extreme point can strongly change $r$.
  \item \textbf{Non-linearity:} you can have a strong relationship but $r \approx 0$ if the pattern is curved.
  \item \textbf{Correlation vs causation:} even a high correlation does not prove that $x$ causes $y$.
\end{itemize}

\section*{2. Exercises (Correlation)}

\subsection*{Exercise 1: Pearson correlation (positive)}
Hours studied vs Score:
\[
x=[1,2,3,4,5],\quad y=[52,55,60,65,68]
\]
Given: $\bar{x}=3$, $\bar{y}=60$.

\paragraph{Step 1: Compute deviations and sums.}
\[
x-\bar{x}=[-2,-1,0,1,2]
\]
\[
y-\bar{y}=[-8,-5,0,5,8]
\]
Now compute:
\[
\sum (x-\bar{x})(y-\bar{y}) = (16+5+0+5+16)=42
\]
\[
\sum (x-\bar{x})^2 = 4+1+0+1+4=10
\]
\[
\sum (y-\bar{y})^2 = 64+25+0+25+64=178
\]

\paragraph{Step 2: Plug into Pearson formula.}
\[
r=\frac{42}{\sqrt{10}\sqrt{178}}=\frac{42}{\sqrt{1780}}\approx 0.9955
\]
\textbf{Interpretation:} Very strong positive linear association between hours studied and score.

\subsection*{Exercise 2: Pearson correlation (negative)}
Price vs Demand:
\[
x=[1,2,3,4,5],\quad y=[80,70,60,50,40]
\]
Here the relationship is perfectly linear: $y=90-10x$.
So:
\[
r=-1
\]
\textbf{Interpretation:} Perfect negative linear relationship.

\subsection*{Exercise 3: $r=0$ but strong relationship}
Let:
\[
x=[-2,-1,0,1,2],\quad y=x^2=[4,1,0,1,4]
\]
Compute means:
\[
\bar{x}=0,\quad \bar{y}=\frac{4+1+0+1+4}{5}=2
\]
Compute numerator:
\[
\sum (x-\bar{x})(y-\bar{y}) = (-2)(2)+(-1)(-1)+0(-2)+1(-1)+2(2)=0
\]
So:
\[
r=0
\]
\textbf{Interpretation:} No \emph{linear} association, but a strong \emph{non-linear} relationship exists ($y$ is determined by $x$).

\subsection*{Exercise 4: Correlation vs causation}
Statement: ``Ice cream sales and drowning incidents are positively correlated.''

\textbf{Best explanation:} A third variable like temperature/season can increase both ice cream sales and swimming activity.
This is called \textbf{confounding}. Correlation alone cannot prove causation.

\section*{3. Skewness}

\subsection*{3.1 What skewness means}
Skewness describes \textbf{asymmetry} in a distribution:
\begin{itemize}
  \item \textbf{Right-skew (positive skew):} long tail to the right; a few very large values.
  \item \textbf{Left-skew (negative skew):} long tail to the left; a few very small values.
\end{itemize}

\subsection*{3.2 Mean vs median (important intuition)}
The mean is pulled toward extreme values more than the median.
So:
\begin{itemize}
  \item Right-skewed: mean $>$ median (high outliers pull mean up).
  \item Left-skewed: mean $<$ median (low outliers pull mean down).
\end{itemize}

\subsection*{3.3 Moment skewness (one common definition)}
Define central moments (divide by $n$):
\[
m_k=\frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^k
\]
Moment skewness:
\[
g_1=\frac{m_3}{m_2^{3/2}}
\]
Notes:
\begin{itemize}
  \item $g_1>0$ indicates right skew; $g_1<0$ indicates left skew.
  \item Some software uses bias-corrected formulas; values can differ slightly.
\end{itemize}

\section*{4. Exercises (Skewness)}

\subsection*{Exercise 5: Identify skewness direction using mean/median}
Dataset A (Income, INR thousands): 20, 22, 23, 24, 25, 26, 27, 28, 60.

Dataset B (Scores): 50, 80, 85, 88, 90, 92, 93, 94, 95, 96.

\paragraph{Dataset A.}
Median is 25 (middle value). Mean is:
\[
\bar{x}=\frac{20+22+23+24+25+26+27+28+60}{9}=\frac{255}{9}\approx 28.33
\]
Since mean $>$ median, the data is right-skewed (positive skew).

\paragraph{Dataset B.}
Median is $(90+92)/2=91$. Mean is:
\[
\bar{x}=\frac{50+80+85+88+90+92+93+94+95+96}{10}=\frac{863}{10}=86.3
\]
Since mean $<$ median, the data is left-skewed (negative skew).

\subsection*{Exercise 6: Compute moment skewness (income)}
Suppose for Dataset A (income) we have:
\[
\bar{x}=28.33,\quad m_2=130.89,\quad m_3=3404.07
\]
Then:
\[
g_1=\frac{3404.07}{(130.89)^{3/2}}\approx 2.27
\]
\textbf{Interpretation:} strongly right-skewed distribution.

\section*{5. Kurtosis}

\subsection*{5.1 What kurtosis means}
Kurtosis is commonly used to describe \textbf{tail heaviness} (how often extreme values occur).
It is often reported as \textbf{excess kurtosis}:
\[
\text{Excess} = \text{kurtosis} - 3
\]
The normal distribution has excess kurtosis 0.

\subsection*{5.2 Moment kurtosis (one common definition)}
Moment kurtosis:
\[
g_2=\frac{m_4}{m_2^2}
\]
Excess kurtosis:
\[
g_2-3
\]
Interpretation:
\begin{itemize}
  \item Excess $>0$: heavier tails (more extreme values than normal).
  \item Excess $<0$: lighter tails (fewer extremes than normal).
\end{itemize}

\section*{6. Exercises (Kurtosis)}

\subsection*{Exercise 7: Excess kurtosis for 1,2,3,4,5}
Dataset: 1, 2, 3, 4, 5. Mean is 3. Deviations: $[-2,-1,0,1,2]$.

\paragraph{Step 1: Compute $m_2$.}
\[
m_2=\frac{4+1+0+1+4}{5}=2
\]
\paragraph{Step 2: Compute $m_4$.}
\[
m_4=\frac{16+1+0+1+16}{5}=\frac{34}{5}=6.8
\]
\paragraph{Step 3: Compute kurtosis and excess.}
\[
g_2=\frac{6.8}{2^2}=1.7,\quad \text{excess}=1.7-3=-1.3
\]
\textbf{Interpretation:} negative excess kurtosis (lighter tails than normal).

\subsection*{Exercise 8: Excess kurtosis for the income example}
Suppose for the income dataset:
\[
m_2=130.89,\quad m_4=112590.30
\]
Then:
\[
g_2=\frac{112590.30}{(130.89)^2}\approx 6.57,\quad \text{excess}\approx 3.57
\]
\textbf{Interpretation:} large positive excess kurtosis indicates heavy tails / extreme values (outliers).

\section*{7. Mini Demo (Python)}
Run this from the lecture folder:
\begin{verbatim}
python demo/correlation_skew_kurt_demo.py
\end{verbatim}

The script:
\begin{itemize}
  \item computes Pearson correlation for:
    \begin{itemize}
      \item hours vs score (positive)
      \item price vs demand (negative)
      \item $x$ vs $x^2$ (non-linear example)
    \end{itemize}
  \item prints correlation values among features in \texttt{data/student\_metrics.csv}
  \item computes moment skewness and excess kurtosis for example univariate datasets
  \item optionally saves plots into \texttt{images/} if \texttt{matplotlib} is installed
\end{itemize}

\section*{References}
\begin{itemize}
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}, Wiley, 7th ed., 2020.
  \item Gupta, S. C., \& Kapoor, V. K. \textit{Fundamentals of Applied Statistics}, Sultan Chand \& Sons, 4th rev. ed., 2007.
  \item McKinney, W. \textit{Python for Data Analysis}, O'Reilly, 2022.
\end{itemize}





% BEGIN SLIDE APPENDIX (AUTO-GENERATED)
\clearpage
\section*{Appendix: Slide Deck Content (Reference)}
\noindent The material below is a reference copy of the slide deck content. Exercise solutions are explained in the main notes where applicable.

\subsection*{Title Slide}
\titlepage
  \vspace{-0.5em}
  \begin{center}
    \small \texttt{https://github.com/tali7c/Statistics-and-Data-Analysis}
  \end{center}
\subsection*{Quick Links}
\centering
  \textbf{Correlation}\hspace{0.6em}
  \textbf{Skewness}\hspace{0.6em}
  \textbf{Kurtosis}\hspace{0.6em}
  \textbf{Demo}\hspace{0.6em}
  \textbf{Summary}
\subsection*{Agenda}
\begin{itemize}
  \item Overview
  \item Correlation
  \item Skewness
  \item Kurtosis
  \item Demo
  \item Summary
\end{itemize}
\subsection*{Learning Outcomes}
\begin{itemize}
    \item Explain correlation and compute Pearson correlation $r$
    \item Relate covariance and correlation, and explain why correlation is scale-free
    \item Identify common pitfalls: outliers, non-linearity, and correlation vs causation
    \item Interpret skewness (right/left skew) and kurtosis (tail heaviness)
  \end{itemize}
\subsection*{From Covariance to Correlation (Recap)}
\begin{itemize}
    \item Covariance tells direction of joint variation, but it depends on units
    \item Correlation standardizes covariance to a unitless number in $[-1,1]$
    \item That makes correlation easier to compare across different datasets
  \end{itemize}
\subsection*{What is Correlation?}
Correlation measures \textbf{linear association} between two variables.
  \vspace{0.6em}
  \begin{itemize}
    \item $r>0$: as $x$ increases, $y$ tends to increase
    \item $r<0$: as $x$ increases, $y$ tends to decrease
    \item $r\approx 0$: no strong \emph{linear} pattern (could still be non-linear)
  \end{itemize}
\subsection*{Pearson Correlation (Formula)}
For paired data $(x_i,y_i)$:
  \[
    r = \frac{\sum_{i=1}^{n}(x_i-\bar{x})(y_i-\bar{y})}
             {\sqrt{\sum_{i=1}^{n}(x_i-\bar{x})^2}\sqrt{\sum_{i=1}^{n}(y_i-\bar{y})^2}}
  \]
  \begin{itemize}
    \item Always between $-1$ and $1$
    \item Unitless (no units)
    \item Sensitive to outliers
  \end{itemize}
\subsection*{Correlation vs Covariance}
\[
    r = \frac{s_{xy}}{s_x s_y}
  \]
  \begin{itemize}
    \item $s_{xy}$: sample covariance (Lecture 02)
    \item $s_x, s_y$: sample standard deviations
    \item Scaling a variable (changing units) does \textbf{not} change $r$
  \end{itemize}
\subsection*{Interpreting $r$ (Rule of Thumb)}
\begin{center}
    \begin{tabular}{ll}
      \toprule
      $|r|$ range & Common description \\
      \midrule
      0.00--0.19 & very weak \\
      0.20--0.39 & weak \\
      0.40--0.59 & moderate \\
      0.60--0.79 & strong \\
      0.80--1.00 & very strong \\
      \bottomrule
    \end{tabular}
  \end{center}
  \vspace{0.4em}
  \textit{Always confirm with a scatter plot.}
\subsection*{Exercise 1: Pearson Correlation (Positive)}
\small
  Hours studied vs Score:
  \vspace{0.4em}
  \begin{center}
    \begin{tabular}{cccccc}
      \toprule
      Hours ($x$) & 1 & 2 & 3 & 4 & 5 \\
      Score ($y$) & 52 & 55 & 60 & 65 & 68 \\
      \bottomrule
    \end{tabular}
  \end{center}
  \vspace{0.4em}
  \normalsize
  Given: $\bar{x}=3$, $\bar{y}=60$, $\sum (x-\bar{x})(y-\bar{y})=42$, $\sum (x-\bar{x})^2=10$, $\sum (y-\bar{y})^2=178$.\\
  \textbf{Task:} Compute $r$ and interpret it.
\subsection*{Solution 1}
\[
    r = \frac{42}{\sqrt{10}\sqrt{178}} = \frac{42}{\sqrt{1780}} \approx 0.9955
  \]
  \textbf{Interpretation:} Very strong positive linear association between hours and score.
\subsection*{Exercise 2: Pearson Correlation (Negative)}
\small
  Price vs Demand:
  \vspace{0.4em}
  \begin{center}
    \begin{tabular}{cccccc}
      \toprule
      Price ($x$) & 1 & 2 & 3 & 4 & 5 \\
      Demand ($y$) & 80 & 70 & 60 & 50 & 40 \\
      \bottomrule
    \end{tabular}
  \end{center}
  \vspace{0.4em}
  \normalsize
  \textbf{Task:} Compute $r$. What does the sign mean?
\subsection*{Solution 2}
Here $y = 90 - 10x$ is a perfect decreasing line.\\
  \[
    r = -1
  \]
  \textbf{Interpretation:} Perfect negative linear relationship.
\subsection*{Exercise 3: $r=0$ Does Not Mean ``No Relationship''}
\small
  Consider:
  \[
    x=[-2,-1,0,1,2],\quad y=x^2=[4,1,0,1,4]
  \]
  \normalsize
  \textbf{Task:} Compute $r$. Is there a relationship between $x$ and $y$?
\subsection*{Solution 3}
\small
  $\bar{x}=0$, $\bar{y}=2$. The numerator $\sum (x-\bar{x})(y-\bar{y})=0$, so:
  \[
    r = 0
  \]
  \normalsize
  \textbf{Key point:} $r=0$ means no \emph{linear} association; here the relationship is strong but non-linear.
\subsection*{Correlation $\neq$ Causation}
\begin{itemize}
    \item Correlation only says ``they move together'' (linearly)
    \item A third variable can cause both (confounding)
    \item Sometimes correlation is accidental (spurious)
    \item Use domain knowledge + experiments/causal reasoning to claim causation
  \end{itemize}
\subsection*{Exercise 4: Interpret a Correlation Claim}
\small
  ``Ice cream sales and drowning incidents are positively correlated.''\\
  \vspace{0.6em}
  Which statement is most correct?
  \begin{enumerate}
    \item Ice cream causes drowning.
    \item Drowning causes ice cream sales.
    \item Both may increase due to a third factor (e.g., temperature/season).
  \end{enumerate}
\subsection*{Solution 4}
\textbf{Correct: (3)}. A confounder like hot weather can increase both swimming (risk) and ice cream sales.
\subsection*{Skewness (Distribution Asymmetry)}
Skewness describes the \textbf{direction of the tail}.
  \vspace{0.6em}
  \begin{itemize}
    \item \textbf{Right-skewed (positive):} long tail to the right (few very large values)
    \item \textbf{Left-skewed (negative):} long tail to the left (few very small values)
    \item Symmetric: tails are similar on both sides
  \end{itemize}
\subsection*{Mean vs Median vs Mode (Heuristic)}
\begin{itemize}
    \item Right-skewed: mean $>$ median $>$ mode
    \item Left-skewed: mean $<$ median $<$ mode
    \item Symmetric: mean $\approx$ median $\approx$ mode
  \end{itemize}
  \vspace{0.4em}
  \textit{Reason: the mean is pulled toward the long tail.}
\subsection*{Moment Skewness (One Common Formula)}
Let $m_k$ be the $k$th central moment (divide by $n$):
  \[
    m_k = \frac{1}{n}\sum_{i=1}^{n}(x_i-\bar{x})^k
  \]
  Moment skewness:
  \[
    g_1 = \frac{m_3}{m_2^{3/2}}
  \]
  \begin{itemize}
    \item $g_1>0$ right-skewed, $g_1<0$ left-skewed
    \item Different software may use small-sample corrections
  \end{itemize}
\subsection*{Exercise 5: Identify Skewness Direction}
\small
  Dataset A (Income, INR thousands):
  \begin{center}
    \begin{tabular}{ccccccccc}
      20 & 22 & 23 & 24 & 25 & 26 & 27 & 28 & 60
    \end{tabular}
  \end{center}
  Dataset B (Scores):
  \begin{center}
    \begin{tabular}{cccccccccc}
      50 & 80 & 85 & 88 & 90 & 92 & 93 & 94 & 95 & 96
    \end{tabular}
  \end{center}
  \normalsize
  \textbf{Task:} For each dataset, decide if it is right-skewed or left-skewed. Predict whether mean $>$ median or mean $<$ median.
\subsection*{Solution 5}
\begin{itemize}
    \item Dataset A: one large value (60) creates a right tail $\Rightarrow$ right-skewed, mean $>$ median
    \item Dataset B: one small value (50) creates a left tail $\Rightarrow$ left-skewed, mean $<$ median
  \end{itemize}
\subsection*{Exercise 6: Compute Moment Skewness}
\small
  For Dataset A (income), suppose:
  \[
    \bar{x}=28.33,\quad m_2=130.89,\quad m_3=3404.07
  \]
  \normalsize
  \textbf{Task:} Compute $g_1=\dfrac{m_3}{m_2^{3/2}}$ and interpret the sign.
\subsection*{Solution 6}
\[
    g_1 = \frac{3404.07}{(130.89)^{3/2}} \approx 2.27
  \]
  \textbf{Interpretation:} Positive and large $\Rightarrow$ strongly right-skewed distribution.
\subsection*{Kurtosis (Tail Heaviness)}
Kurtosis summarizes how heavy the tails are (and how often extreme values appear).
  \vspace{0.6em}
  \begin{itemize}
    \item Often reported as \textbf{excess kurtosis} = kurtosis $-3$
    \item Normal distribution has excess kurtosis $0$
    \item Positive excess: heavier tails; negative excess: lighter tails
  \end{itemize}
\subsection*{Moment Kurtosis (One Common Formula)}
Moment kurtosis:
  \[
    g_2 = \frac{m_4}{m_2^2}
  \]
  Excess kurtosis:
  \[
    \text{Excess} = g_2 - 3
  \]
  \begin{itemize}
    \item If excess $>0$, more extreme values than normal (heavy tails)
    \item If excess $<0$, fewer extremes than normal (light tails)
  \end{itemize}
\subsection*{Exercise 7: Excess Kurtosis (Small Symmetric Data)}
\small
  Dataset: 1, 2, 3, 4, 5. \\
  Mean = 3, deviations: $[-2,-1,0,1,2]$.
  \vspace{0.4em}

  \normalsize
  \textbf{Task:} Compute $m_2$, $m_4$, then $g_2$ and excess kurtosis.
\subsection*{Solution 7}
\small
  \[
    m_2 = \frac{4+1+0+1+4}{5} = 2
  \]
  \[
    m_4 = \frac{16+1+0+1+16}{5} = \frac{34}{5}=6.8
  \]
  \[
    g_2 = \frac{6.8}{2^2} = 1.7,\quad \text{excess} = 1.7-3=-1.3
  \]
  \normalsize
  \textbf{Interpretation:} Negative excess $\Rightarrow$ lighter tails than normal (platykurtic).
\subsection*{Exercise 8: Excess Kurtosis (Income Example)}
\small
  For the income dataset (Exercise 6), suppose:
  \[
    m_2 = 130.89,\quad m_4 = 112590.30
  \]
  \normalsize
  \textbf{Task:} Compute $g_2=\dfrac{m_4}{m_2^2}$ and excess kurtosis. Interpret.
\subsection*{Solution 8}
\[
    g_2 \approx \frac{112590.30}{(130.89)^2} \approx 6.57,\quad \text{excess}\approx 3.57
  \]
  \textbf{Interpretation:} Large positive excess $\Rightarrow$ heavy tails / extreme values (outliers).
\subsection*{Common Pitfalls (Skewness \& Kurtosis)}
\begin{itemize}
    \item Small samples can give unstable skewness/kurtosis values
    \item Different formulas exist (bias corrections), so values may differ across tools
    \item Always verify with plots (histogram/boxplot) and context
  \end{itemize}
\subsection*{Mini Demo (Python)}
Run:
  \begin{center}
    \texttt{python demo/correlation\_skew\_kurt\_demo.py}
  \end{center}
  \vspace{0.4em}
  What it does:
  \begin{itemize}
    \item Computes Pearson correlation for three paired datasets
    \item Prints correlation matrix for \texttt{data/student\_metrics.csv}
    \item Computes moment skewness and excess kurtosis for example distributions
    \item (Optional) Saves plots to \texttt{images/} if matplotlib is installed
  \end{itemize}
\subsection*{Summary}
\begin{itemize}
    \item Correlation standardizes covariance to $[-1,1]$ and measures linear association
    \item $r=0$ does not mean independence; it only indicates no linear relation
    \item Skewness describes tail direction; mean is pulled toward the tail
    \item Excess kurtosis relates to tail heaviness and outliers
  \end{itemize}
  \vspace{0.6em}
  \textbf{Exit question:} Give one real-life example where correlation might be misleading and explain why.
% END SLIDE APPENDIX (AUTO-GENERATED)

\end{document}
