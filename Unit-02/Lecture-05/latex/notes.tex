\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 02 -- Lecture 05 Notes\\Dimensional Summaries and Distributions}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{What You Will Learn (Beginner-Friendly)}
In earlier lectures we learned measures of center (mean/median/mode) and spread (IQR, variance, std).
In this lecture we scale up that idea:
\begin{itemize}
  \item A dataset usually has many columns (dimensions/features).
  \item Each feature can have a different distribution shape.
  \item We need per-feature (dimensional) summaries and distribution thinking.
\end{itemize}

By the end, you should be able to:
\begin{itemize}
  \item compute and interpret per-feature summaries,
  \item recognize common distribution shapes (symmetric, skewed, bimodal),
  \item explain why shape matters for choosing the right summary statistic.
\end{itemize}

\section*{1. Dimensional (Per-Feature) Summaries}
\subsection*{1.1 Definition}
A \textbf{dimensional summary} means summarizing each feature/column separately using:
\begin{itemize}
  \item center: mean/median,
  \item spread: std/IQR,
  \item range: min/max,
  \item quartiles: $Q_1, Q_3$.
\end{itemize}

\paragraph{Why it helps.}
If you have 20 columns, you can quickly identify:
\begin{itemize}
  \item which features have large variability,
  \item which features have outliers,
  \item which features are likely skewed,
  \item which features might need transformation (like log).
\end{itemize}

\subsection*{Exercise 1 (solution)}
Given:
\begin{itemize}
  \item A: mean=50, median=50 $\Rightarrow$ roughly symmetric (likely)
  \item B: mean=80, median=60 $\Rightarrow$ right-skewed (high values pull mean upward)
  \item C: mean=60, median=75 $\Rightarrow$ left-skewed (low values pull mean downward)
\end{itemize}
This rule is a \textbf{heuristic}. Always confirm using a histogram or boxplot.

\section*{2. Distribution Shapes}
\subsection*{2.1 Symmetric distributions}
For symmetric distributions (often approximately normal):
\begin{itemize}
  \item mean $\approx$ median,
  \item left and right tails are similar,
  \item mean and std are often reasonable summaries.
\end{itemize}

\subsection*{2.2 Right-skewed distributions}
Right-skewed means there is a long tail on the right.
Example: income.
Most people have moderate incomes, but a few people have very high incomes.
This pulls the mean upward, so mean $>$ median is common.

\subsection*{2.3 Left-skewed distributions}
Left-skewed means there is a long tail on the left (a few very low values).
Example: marks on an easy exam where many students score very high.
Mean $<$ median can occur.

\subsection*{2.4 Bimodal distributions}
Bimodal means two peaks. This often happens when the data mixes two sub-populations.
Example: commute times might be short for hostel students and long for day scholars.

\subsection*{Exercise 2 (solution)}
Commute times: 10, 12, 15, 18, 20, 60, 65, 70\\
Mean:
\[
\frac{270}{8}=33.75
\]
Median:
\[
\frac{18+20}{2}=19
\]
Interpretation: the mean is not typical because the data has two clusters and very few values around 34.

\subsection*{Exercise 3 (solution)}
Daily income is most likely right-skewed.

\section*{3. Outliers and Robust Summaries}
\subsection*{3.1 Outliers}
Outliers are values that are unusually far from the rest.
They can be:
\begin{itemize}
  \item errors (wrong entry, sensor fault),
  \item or true extremes (rare but real cases).
\end{itemize}
So we should detect them and think, not blindly delete them.

\subsection*{3.2 IQR rule (recap)}
Compute:
\[
\mathrm{IQR}=Q_3-Q_1
\]
Fences:
\[
Q_1 - 1.5\mathrm{IQR}, \quad Q_3 + 1.5\mathrm{IQR}
\]
Values outside fences are flagged as potential outliers.

\subsection*{Exercise 4 (solution)}
Dataset: 10, 12, 13, 14, 15, 16, 40\\
Median = 14; $Q_1=12$; $Q_3=16$; IQR = 4\\
Upper fence = 16 + 1.5(4) = 22\\
So 40 is an outlier by the IQR rule.

\subsection*{Exercise 5 (solution)}
For income (right-skewed), median + IQR is usually better than mean + std because it is robust.

\subsection*{Exercise 6 (solution)}
Mean(hours) = 4 and mean(score) = 60.

\section*{4. Mini Demo (Python)}
Run from the lecture folder:
\begin{verbatim}
python demo/dimensional_summaries_distributions_demo.py
\end{verbatim}

It uses \texttt{data/multi\_feature\_distributions.csv} and prints a dimensional summary:
\begin{itemize}
  \item mean, median, std, min/max, quartiles, and a simple skewness estimate.
\end{itemize}
If matplotlib is installed, it also saves \texttt{images/hists\_grid.png}.

\section*{References}
\begin{itemize}
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}, Wiley, 7th ed., 2020.
  \item Freedman, D., Pisani, R., \& Purves, R. \textit{Statistics}, W. W. Norton, 4th ed., 2007.
  \item McKinney, W. \textit{Python for Data Analysis}, O'Reilly, 2022.
\end{itemize}

\end{document}

