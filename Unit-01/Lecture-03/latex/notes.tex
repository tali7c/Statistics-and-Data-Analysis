\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 01 -- Lecture 03 Notes\\Preprocessing Pipelines and Exploratory Data Analysis (EDA)}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{What You Will Learn}
In this lecture we move from individual cleaning techniques to a full workflow:
\begin{itemize}
  \item how to organize preprocessing as a \textbf{pipeline},
  \item how to run a basic \textbf{EDA} (exploratory data analysis),
  \item how to choose plots based on variable types,
  \item and how to avoid \textbf{data leakage}.
\end{itemize}

\section*{1. Preprocessing Pipelines}

\subsection*{1.1 What is a pipeline?}
A pipeline is an ordered set of steps that you apply consistently to data.
For example:
\begin{enumerate}
  \item read raw data,
  \item clean and validate,
  \item create summaries and plots,
  \item save cleaned data and reports.
\end{enumerate}

\subsection*{1.2 Why pipelines matter}
Pipelines are important because they:
\begin{itemize}
  \item make your work \textbf{reproducible} (you can re-run on new data),
  \item reduce errors (clear steps, less manual editing),
  \item make collaboration easier (others can follow the same steps),
  \item help avoid \textbf{data leakage} in machine learning workflows.
\end{itemize}

\subsection*{Exercise 1 (solution)}
One reasonable order is:
\begin{enumerate}
  \item Load raw data
  \item Check missingness
  \item Fix data types + invalid ranges
  \item EDA plots
  \item Save cleaned dataset
\end{enumerate}

\section*{2. Exploratory Data Analysis (EDA)}

\subsection*{2.1 What is EDA?}
EDA is the first structured look at the dataset to understand:
\begin{itemize}
  \item what the data contains,
  \item how clean it is,
  \item what the distributions look like,
  \item and what relationships might exist.
\end{itemize}

EDA is not only about plots. It also includes summary tables, missingness reports, and sanity checks.

\subsection*{2.2 Minimum EDA checklist}
\begin{enumerate}
  \item \textbf{Shape and columns}: number of rows and columns; column meanings.
  \item \textbf{Data types}: numeric/categorical/datetime.
  \item \textbf{Missingness}: missing \% per column.
  \item \textbf{Ranges}: are values possible? (0--100\%, CGPA 0--10, etc.)
  \item \textbf{Univariate summaries}: \texttt{describe()} for numeric; counts for categories.
  \item \textbf{Relationships}: scatter plots and correlations for numeric features.
  \item \textbf{Group comparisons}: program-wise or gender-wise summaries.
\end{enumerate}

\subsection*{2.3 Plot selection}
\begin{itemize}
  \item Numeric (one variable): histogram / boxplot
  \item Categorical (one variable): bar chart (counts)
  \item Numeric vs numeric: scatter plot
  \item Numeric vs categorical: boxplot grouped by category
  \item Many numeric features: correlation matrix/heatmap
\end{itemize}

\subsection*{Exercise 2 (solution)}
\begin{itemize}
  \item Distribution of \texttt{final\_marks}: histogram or boxplot.
  \item Compare \texttt{final\_marks} across \texttt{program}: boxplot grouped by program.
  \item Relationship between \texttt{study\_hours\_week} and \texttt{final\_marks}: scatter plot.
\end{itemize}

\section*{3. Data Leakage (Very Important)}

\subsection*{3.1 What is leakage?}
Leakage happens when we accidentally use information from the test set (future/unseen data) during training.
This makes the results look better than reality.

Common leakage examples:
\begin{itemize}
  \item computing scaling parameters using the full dataset before train/test split,
  \item imputing missing values using the full dataset mean/median before split,
  \item using future data to predict the past (time series leakage).
\end{itemize}

\subsection*{Exercise 3 (solution)}
Not correct. The fix is:
\begin{itemize}
  \item split into train/test first,
  \item compute scaling/imputation rules on \textbf{train only},
  \item apply them to test.
\end{itemize}

\section*{4. Mini Demo (Python)}
Run from the lecture folder:
\begin{verbatim}
python demo/pipeline_eda_demo.py
\end{verbatim}

The script does:
\begin{itemize}
  \item reads \texttt{data/case\_study.csv},
  \item cleans and validates (range checks + median imputation),
  \item saves \texttt{data/case\_study\_clean.csv},
  \item saves group summary and correlation matrix as CSV,
  \item saves four plots into \texttt{images/}.
\end{itemize}

\section*{References}
\begin{itemize}
  \item McKinney, W. \textit{Python for Data Analysis}. O'Reilly, 2022.
  \item Tukey, J. W. \textit{Exploratory Data Analysis}. Addison-Wesley, 1977.
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}. Wiley, 7th ed., 2020.
\end{itemize}

\end{document}

