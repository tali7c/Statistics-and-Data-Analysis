\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{geometry}
\usepackage{amsmath}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{graphicx}
\geometry{margin=1in}

\title{Statistics and Data Analysis\\Unit 01 -- Lecture 04 Notes\\In-class Activity: Cleaning + Summary Tables + Plots}
\author{Tofik Ali}
\date{\today}

\begin{document}
\maketitle

\section*{Purpose of This Activity}
In real projects, you rarely receive a perfectly clean dataset.
Before you can compute statistics or build models, you must first:
\begin{itemize}
  \item understand what each column means,
  \item detect problems (missing values, invalid entries, outliers),
  \item apply clear cleaning rules,
  \item and then produce summary tables and plots that answer simple questions.
\end{itemize}

\paragraph{Repository.}
\texttt{https://github.com/tali7c/Statistics-and-Data-Analysis}

\section*{Learning Outcomes (What You Should Be Able To Do)}
After completing this activity, you should be able to:
\begin{enumerate}
  \item load a CSV in Python and inspect shape, head, and data types,
  \item compute missingness and spot invalid values,
  \item write and justify basic cleaning rules,
  \item engineer simple features from existing columns,
  \item compute group summaries using \texttt{groupby},
  \item generate and interpret three basic plots.
\end{enumerate}

\section*{1. Dataset Description}
File: \texttt{data/campus\_cafe\_transactions.csv}

\subsection*{1.1 What one row represents}
Each row is one transaction at a campus cafe/store.

\subsection*{1.2 Column meanings}
\begin{itemize}
  \item \texttt{txn\_id}: transaction id (identifier).
  \item \texttt{date}: transaction date (should become a datetime).
  \item \texttt{category}: product category (Snacks/Drinks/Stationery).
  \item \texttt{payment\_mode}: Cash/UPI/Card.
  \item \texttt{units}: number of items purchased (should be non-negative).
  \item \texttt{unit\_price}: price per unit in INR (should be positive).
  \item \texttt{discount\_pct}: discount percentage (0 means no discount).
\end{itemize}

\paragraph{Important.}
This dataset intentionally contains:
\begin{itemize}
  \item missing values (blank cells),
  \item invalid values (e.g., negative units),
  \item and outliers (unrealistic price/discount).
\end{itemize}
Your job is to clean it in a transparent, reproducible way.

\section*{2. Step-by-Step Instructions}

\subsection*{2.1 Task A: Load and inspect (first 5 minutes)}
Run these steps in a Python script or notebook:
\begin{verbatim}
import pandas as pd

df = pd.read_csv("data/campus_cafe_transactions.csv")
print(df.shape)
print(df.head())
print(df.dtypes)
\end{verbatim}

What to check:
\begin{itemize}
  \item Are numbers stored as numbers (or as strings)?
  \item Are there blanks in numeric columns?
  \item Does \texttt{date} look like a date?
\end{itemize}

\subsection*{2.2 Task B: Missingness (quick diagnostic)}
Compute missing percentage per column:
\begin{verbatim}
missing_pct = df.isna().mean().sort_values(ascending=False) * 100
print(missing_pct)
\end{verbatim}

\paragraph{Why we do this.}
If a column is mostly missing, dropping it may be reasonable.
If only a few values are missing, imputation is often better than dropping rows.

\subsection*{2.3 Task C: Cleaning rules (the most important part)}
Cleaning is not ``one correct answer''. The key is to apply \textbf{defensible rules}.
For this activity, use rules like the following:

\paragraph{Rule 1: Convert types.}
\begin{itemize}
  \item parse \texttt{date} as datetime,
  \item convert \texttt{units}, \texttt{unit\_price}, \texttt{discount\_pct} to numeric,
  \item trim whitespace in categorical columns.
\end{itemize}

\paragraph{Rule 2: Handle missing discounts.}
If \texttt{discount\_pct} is missing, fill it with 0 because in most sales systems, a missing discount usually means ``no discount recorded''.

\paragraph{Rule 3: Handle missing units (imputation).}
If only a few \texttt{units} values are missing, impute them with the median units.
Median is used because it is robust (a few large purchases do not strongly affect the median).

\paragraph{Rule 4: Handle negative units (invalid).}
If \texttt{units} is negative, drop the row.
Negative units would mean ``selling -1 items'', which is physically impossible for a purchase transaction.

\paragraph{Rule 5: Cap discount outliers.}
Discounts like 150\% do not make sense for normal retail transactions.
Cap \texttt{discount\_pct} to a reasonable range, e.g., 0--50.
This prevents absurd discounts from creating negative or near-zero net amounts.

\paragraph{Rule 6: Handle price outliers.}
If \texttt{unit\_price} is unreasonably high (e.g., greater than 200 INR for this small campus dataset),
replace it with the median price of its \texttt{category}.
The reasoning: within a category, typical prices are similar, so category median is a stable fallback.

\subsection*{2.4 Task D: Feature engineering}
Create three new columns:
\begin{itemize}
  \item \texttt{gross\_amount} = \texttt{units} $\times$ \texttt{unit\_price}
  \item \texttt{net\_amount} = \texttt{gross\_amount} $\times (1-\texttt{discount\_pct}/100)$
  \item \texttt{is\_weekend} = 1 if Saturday/Sunday else 0
\end{itemize}

\paragraph{Why this matters.}
Raw columns are often not directly useful. The engineered \texttt{net\_amount} is the key value that we will summarize and plot.

\subsection*{2.5 Task E: Summary tables}
Compute:
\begin{itemize}
  \item total net revenue by \texttt{category}
  \item total net revenue by \texttt{payment\_mode}
  \item top 5 transactions by \texttt{net\_amount}
  \item daily net revenue (sum of net amounts per day)
\end{itemize}

Typical patterns:
\begin{verbatim}
rev_by_cat = df.groupby("category")["net_amount"].sum()
rev_by_pay = df.groupby("payment_mode")["net_amount"].sum()
top5 = df.sort_values("net_amount", ascending=False).head(5)
daily = df.groupby(df["date"].dt.date)["net_amount"].sum()
\end{verbatim}

\subsection*{2.6 Task F: Plots (and what to look for)}
\begin{enumerate}
  \item \textbf{Bar chart (revenue by category):} which category dominates?
  \item \textbf{Histogram (net amount):} do we have many small transactions and a few big ones?
  \item \textbf{Line chart (daily revenue):} is revenue stable day-to-day, or spiky?
\end{enumerate}

\section*{3. Expected Results (After Applying the Example Cleaning Rules)}
If you run the provided solution script (see next section), you should get results close to these:

\subsection*{3.1 Net revenue by category}
\begin{center}
\begin{tabular}{lrr}
  \toprule
  Category & Count & Net Revenue (INR) \\
  \midrule
  Snacks & 9 & 1129.25 \\
  Drinks & 8 & 368.00 \\
  Stationery & 7 & 283.90 \\
  \bottomrule
\end{tabular}
\end{center}

\paragraph{Interpretation.}
Snacks dominate revenue in this sample because there are several snack transactions and also one very large snack purchase.
Even after cleaning, a few large transactions can strongly influence totals.

\subsection*{3.2 Net revenue by payment mode}
\begin{center}
\begin{tabular}{lrr}
  \toprule
  Mode & Count & Net Revenue (INR) \\
  \midrule
  UPI & 12 & 1124.15 \\
  Cash & 6 & 304.00 \\
  Card & 6 & 353.00 \\
  \bottomrule
\end{tabular}
\end{center}

\paragraph{Interpretation.}
UPI has the highest count and highest total revenue, which suggests it is the preferred payment mode in this small dataset.

\subsection*{3.3 Top transactions (by net amount)}
The largest transaction is:
\begin{itemize}
  \item \texttt{txn\_id=5009} with \texttt{net\_amount=365.0}.
\end{itemize}
This row originally had an unrealistic \texttt{unit\_price=500}.
After cleaning, the unit price is replaced with the category median (36.5 for Snacks), producing a sensible net amount.

\section*{4. Provided Solution Script (Mini Demo)}
After you attempt the activity yourself, run:
\begin{verbatim}
python demo/activity_solution.py
\end{verbatim}

It will generate:
\begin{itemize}
  \item \texttt{data/campus\_cafe\_clean.csv}
  \item \texttt{data/revenue\_by\_category.csv}
  \item \texttt{data/revenue\_by\_payment.csv}
  \item \texttt{data/daily\_revenue.csv}
  \item \texttt{data/top\_transactions.csv}
  \item plots in \texttt{images/}:
    \texttt{revenue\_by\_category.png}, \texttt{net\_amount\_hist.png}, \texttt{daily\_revenue.png}
\end{itemize}

\section*{5. Common Mistakes (And How To Avoid Them)}
\begin{itemize}
  \item \textbf{Forgetting type conversion:} always run \texttt{pd.to\_numeric} and \texttt{pd.to\_datetime}.
  \item \textbf{Dropping too many rows:} if missingness is small, prefer imputation.
  \item \textbf{Blindly deleting outliers:} first decide if it is an error or a true extreme.
  \item \textbf{Not writing rules:} if rules are not documented, results cannot be trusted or reproduced.
  \item \textbf{Not saving outputs:} always save cleaned data and plots.
\end{itemize}

\section*{6. Extension Questions (Optional)}
If you finish early, try any two:
\begin{enumerate}
  \item Compare weekend vs weekday revenue using \texttt{is\_weekend}.
  \item Compute average discount by category.
  \item Count transactions per day and compare with daily revenue.
  \item Identify whether ``Snacks'' dominate because of quantity or price.
\end{enumerate}

\section*{References}
\begin{itemize}
  \item McKinney, W. \textit{Python for Data Analysis}. O'Reilly, 2022.
  \item Montgomery, D. C., \& Runger, G. C. \textit{Applied Statistics and Probability for Engineers}. Wiley, 7th ed., 2020.
\end{itemize}

\end{document}

